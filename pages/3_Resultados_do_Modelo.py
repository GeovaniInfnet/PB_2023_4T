# Importa√ß√£o das bibliotecas necess√°rias
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error

# Carrega o arquivo CSV e valida os dados
@st.cache_data
def upload_file():
    try:
        # Leitura do arquivo CSV
        df = pd.read_csv('Credit_Card_Customers.csv')

        # Verifica se o arquivo possui as colunas necess√°rias
        if {'Customer_Age', 'Gender', 'Dependent_count', 
            'Income_Category','Card_Category', 'Avg_Open_To_Buy',
            'Total_Trans_Amt', 'Total_Trans_Ct', 'Credit_Limit',
            'Avg_Utilization_Ratio'}.issubset(df.columns):
            return (True, df)
        else:
            # Se o arquivo n√£o possuir as colunas adequadas, exibe um erro  
            st.error('O arquivo n√£o possui o formato adequado!', icon="üö®")
            return (False, None)  
    except FileNotFoundError:        
        # Se o arquivo n√£o for encontrado, exibe uma mensagem informativa 
        st.info("""
            N√£o foram encontrados os dados sobre a movimenta√ß√£o financeira dos clientes!\n
            Verifique se o arquivo 'Credit_Card_Customers.csv' est√° na pasta raiz.""", icon="‚ÑπÔ∏è") 
        return (False, None)

# Fun√ß√£o para aplicar transforma√ß√µes logar√≠tmicas em algumas colunas assim√©tricas
def transform_log_features(data):
    # Aplica log em algumas vari√°veis assim√©tricas
    data['Avg_Open_To_Buy'] = data['Avg_Open_To_Buy'].apply(lambda s: np.log(s))
    data['Total_Trans_Amt'] = data['Total_Trans_Amt'].apply(lambda s: np.log(s))
    data['Total_Trans_Ct'] = data['Total_Trans_Ct'].apply(lambda s: np.log(s))
    
    # Realiza a transforma√ß√£o 'yeo-johnson' na vari√°vel 'Avg_Utilization_Ratio'    
    data_transformed, _ = stats.yeojohnson(data['Avg_Utilization_Ratio'])
    data['Avg_Utilization_Ratio'] = data_transformed    
    return data

# Fun√ß√£o que realiza a codifica√ß√£o de vari√°veis categ√≥ricas utilizando LabelEncoder
def encode_features(data):
    dict_encoders = {}

    # Guarda a refer√™ncia do objeto (para desfazer a transforma√ß√£o) e realiza a codifica√ß√£o das vari√°veis
    dict_encoders['Gender'] = [LabelEncoder(), 'Gender_Encoded']
    data['Gender_Encoded'] = dict_encoders['Gender'][0].fit_transform(data['Gender'].values)

    dict_encoders['Income_Category'] = [LabelEncoder(), 'IncomeCategory_Encoded']
    data['IncomeCategory_Encoded'] = dict_encoders['Income_Category'][0].fit_transform(data['Income_Category'].values)

    dict_encoders['Card_Category'] = [LabelEncoder(), 'CardCategory_Encoded']
    data['CardCategory_Encoded'] = dict_encoders['Card_Category'][0].fit_transform(data['Card_Category'].values)
    
    return data, dict_encoders

# Fun√ß√£o que realiza todo o pr√©-processamento dos dados
@st.cache_data
def pre_processing(data):
    data = transform_log_features(data)
    data, dict_encoders = encode_features(data)

    # Cria um novo dataframe com as colunas categ√≥ricas codificadas
    bank_model = data[[
        'Customer_Age',
        'Gender_Encoded',
        'Dependent_count',
        'IncomeCategory_Encoded',
        'CardCategory_Encoded',
        'Avg_Open_To_Buy',
        'Total_Trans_Amt',
        'Total_Trans_Ct',    
        'Avg_Utilization_Ratio',
        'Credit_Limit'
    ]].copy()

    # Cria um array com as vari√°veis independentes
    X = bank_model.iloc[:, :9].values

    # Cria um array com a vari√°vel dependente
    y = bank_model.iloc[:, 9].values    
    return X, y, dict_encoders, bank_model

# Fun√ß√£o para treinar o modelo de regress√£o linear
@st.cache_data
def model_training(X_train_scaled, y_train, X_test_scaled, y_test):
    model = LinearRegression()
    model.fit(X_train_scaled, y_train)
    
    y_pred = model.predict(X_test_scaled)

    mape = mean_absolute_percentage_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mse = mean_squared_error(y_test, y_pred)

    return y_pred, mae, mape, mse, rmse

# Fun√ß√£o para plotar o gr√°fico de regress√£o
def plot_regression(X_test_inverse, feature_idx, feature_name, encoded=False, dict_encoders=None):
    plt.figure(figsize=(10,4))

    # Seleciona somente os dados pedidos pelo plot
    X_test_plot = X_test_inverse[:, feature_idx]

    # Invertendo a codifica√ß√£o do LabelEncoder nos dados de teste
    if encoded:
        X_test_plot = dict_encoders[feature_name][0].inverse_transform(X_test_plot.astype(int))

    # Plota o gr√°fico de dispers√£o com os dados reais
    ax = sns.scatterplot(x=X_test_plot, y=y_test, label=feature_name)

    # Plota a linha de regress√£o
    sns.lineplot(x=X_test_plot, y=y_pred, color='red', label='Regress√£o Linear', errorbar=None, ax=ax)

    # Cria um t√≠tulo e altera o r√≥tulo dos eixos
    ax.set_title('Regress√£o Linear')
    ax.set_xlabel(f'Vari√°vel Independente - {feature_name}')
    ax.set_ylabel('Vari√°vel Dependente - Credit_Limit')
 
    return ax.figure

# Configura√ß√£o da p√°gina com layout amplo e t√≠tulo
st.set_page_config(layout='wide')
st.title('Resultados do Modelo')

# Carrega o arquivo e verifica se foi carregado com sucess  
file_loaded, bank = upload_file()

if file_loaded:
    bank_selection = bank.copy()
    
    # Pr√©-processamento dos dados
    X, y, dict_encoders, bank_model = pre_processing(bank)

    # 70% ser√£o usados para treino. 30% ser√£o usados para teste.
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

    # Transforma√ß√£o de escala das vari√°veis independentes
    ss_train = StandardScaler()
    X_train_scaled = ss_train.fit_transform(X_train)

    ss_test = StandardScaler()
    X_test_scaled = ss_test.fit_transform(X_test)
    
    # Treinamento e avalia√ß√£o do modelo
    y_pred, mae, mape, mse, rmse = model_training(X_train_scaled, y_train, X_test_scaled, y_test)

    # Se√ß√£o expans√≠veis para m√©tricas e visualiza√ß√£o dos resultados    
    with st.expander('M√©tricas'):
        dict_metric = {
            'MAE (Mean Absolute Error)': mae,
            'MAPE (Mean Absolute Percentage Error)': mape,
            'MSE (Mean Squared Error)': mse,
            'RMSE (Root Mean Squared Error)': rmse
        }

        df_metric = pd.DataFrame(dict_metric.items(), columns=['M√©trica', 'Valor'])
        st.data_editor(df_metric, disabled=True, hide_index=True, use_container_width=True)

    # Se√ß√£o expans√≠veis para visualiza√ß√£o dos resultados 
    with st.expander('Visualiza√ß√£o dos Resultados'):
        # Inverte a escala nos dados de teste antes da plotagem
        X_test_inverse = ss_test.inverse_transform(X_test)

        # Lista de vari√°veis do banco de dados original
        var_list = bank_selection.drop('Credit_Limit', axis=1).columns.to_list()
        features = st.multiselect('Selecione a vari√°vel:', options=var_list)
        categorical_list = bank.select_dtypes(exclude='number').columns.to_list()
        
        if features:
            for feature in features:
                if feature in categorical_list:
                    # Plota gr√°fico de dispers√£o para vari√°veis categ√≥ricas codificadas
                    st.pyplot(plot_regression(X_test_inverse, 
                                              bank_model.columns.get_loc(dict_encoders[feature][1]), 
                                              feature_name=feature, 
                                              encoded=True, 
                                              dict_encoders=dict_encoders))
                else:
                    # Plota gr√°fico de dispers√£o para vari√°veis num√©ricas
                    st.pyplot(plot_regression(X_test_inverse,
                                              bank_model.columns.get_loc(feature), 
                                              feature_name=feature))
